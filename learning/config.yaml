# defaults:
#     - override hydra/launcher: submitit_local
# training
num_envs : 1024
batch_size : 1024
# environment
benchmark: dm_control
task: CheetahRun
obs: state
exp_name : test

# evaluation
checkpoint: ???
impl : warp #or jax
eval_with_training_env : false #added
num_evals : 20

#policy
policy : ppo
asymmetric_critic: true
distributional_q : false

# logging
wandb_project: test
wandb_entity: ??? 
wandb_silent: false
use_wandb: true
save_csv: true
comment: ''

#domain randomization
randomization: true
final_randomization: true
custom_wrapper: true
dr_train_ratio : 1.
group: ???
# epopt
epsilon : 0.1
# GMMVI cfg
scheduler_lr : 0.2
scheduler_window_size: 20
start_beta : 0.
end_beta : -1.
scheduler_mode : 'linear'  # 'linear' or 'exp'

#sampler cfg
sampler_update_freq : 1           #set 10 to take long horizon information despite of policy_updates.
n_sampler_iters : 50                #need to consider in flow 
success_threshold : .6
success_rate_condition : 0.7
gamma : 0.
beta : 1.
use_scheduling : False
# misc
save_video: true
save_agent: true
seed: 42

# convenience
work_dir: ???
# task_title: ???
# multitask: ???
# tasks: ???
# obs_shape: ???
# action_dim: ???
# episode_length: ???
# obs_shapes: ???
# action_dims: ???
# episode_lengths: ???
# seed_steps: ???
# bin_size: ???

#simba
simba : false

#tdmpc
horizon: 3

#m2td3
omega_distance_threshold: 0.1