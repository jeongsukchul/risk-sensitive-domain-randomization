# defaults:
#     - override hydra/launcher: submitit_local
# training
num_envs : 1024
batch_size : 1024
# environment
benchmark: dm_control
task: CheetahRun
obs: state
exp_name : test

# evaluation
checkpoint: ???
impl : warp #or jax
eval_with_training_env : false #added
num_evals : 20

#policy
policy : ppo
asymmetric_critic: true
distributional_q : false

# logging
wandb_project: test-riskppo
wandb_entity: tjrcjf410-seoul-national-university
wandb_silent: false
use_wandb: true
save_csv: true
comment: ''

#domain randomization
randomization: true
final_randomization: true
custom_wrapper: true
dr_train_ratio : 1.

#sampler cfg
sampler_update_freq : 10           #set 10 to take long horizon information despite of policy_updates.
n_sampler_iters : 50                #need to consider in flow and gmm
success_threshold : .7
success_rate_condition : 0.7
gamma : 0.
beta : 2.
# misc
save_video: true
save_agent: true
seed: 1

# convenience
work_dir: ???
task_title: ???
multitask: ???
tasks: ???
obs_shape: ???
action_dim: ???
episode_length: ???
obs_shapes: ???
action_dims: ???
episode_lengths: ???
seed_steps: ???
bin_size: ???

#simba
simba : false

#tdmpc
horizon: 3

#m2td3
omega_distance_threshold: 0.1